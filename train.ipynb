{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82359ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ PyTorch device: cuda:0\n",
      "âœ“ Quantum device: default.qubit (torch interface, backprop)\n",
      "ðŸ”¬ Initializing Hybrid Quantum GAN\n",
      "   Device: cuda:0\n",
      "   Qubits: 5 (1 ancillary)\n",
      "   Generators: 4 (patch size: 16)\n",
      "\n",
      "Loaded 178 samples of digit '0'\n",
      "ðŸš€ Starting training for 50 epochs...\n",
      "--------------------------------------------------\n",
      "Epoch   0 | Loss D: 1.2994 | Loss G: 0.7212\n",
      "Epoch  10 | Loss D: 0.0440 | Loss G: 4.4389\n",
      "Epoch  20 | Loss D: 0.0073 | Loss G: 6.2381\n",
      "Epoch  30 | Loss D: 0.0032 | Loss G: 6.9651\n",
      "Epoch  40 | Loss D: 0.0017 | Loss G: 7.1871\n",
      "--------------------------------------------------\n",
      "âœ… Training Complete!\n",
      "Checkpoint saved to checkpoint.pt\n",
      "Saved training progress to training_progress.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train.py\n",
    "\"\"\"\n",
    "Main training script for Hybrid Quantum-Classical GAN.\n",
    "Run this file to start training.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import config\n",
    "import dataset\n",
    "import models\n",
    "import utils\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Main training loop.\"\"\"\n",
    "    \n",
    "    # --- Setup ---\n",
    "    utils.set_seed()\n",
    "    print(f\"ðŸ”¬ Initializing Hybrid Quantum GAN\")\n",
    "    print(f\"   Device: {config.DEVICE}\")\n",
    "    print(f\"   Qubits: {config.N_QUBITS} ({config.N_A_QUBITS} ancillary)\")\n",
    "    print(f\"   Generators: {config.N_GENERATORS} (patch size: {config.PATCH_SIZE})\")\n",
    "    print()\n",
    "    \n",
    "    # Data\n",
    "    dataloader = dataset.get_dataloader()\n",
    "    \n",
    "    # Models\n",
    "    generator = models.PatchQuantumGenerator().to(config.DEVICE)\n",
    "    discriminator = models.Discriminator().to(config.DEVICE)\n",
    "    \n",
    "    # Loss & Optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    optG = optim.SGD(generator.parameters(), lr=config.LR_GENERATOR)\n",
    "    optD = optim.SGD(discriminator.parameters(), lr=config.LR_DISCRIMINATOR)\n",
    "    \n",
    "    # Labels\n",
    "    real_labels = torch.ones(config.BATCH_SIZE, 1, device=config.DEVICE)\n",
    "    fake_labels = torch.zeros(config.BATCH_SIZE, 1, device=config.DEVICE)\n",
    "    \n",
    "    # History for visualization\n",
    "    history_images = []\n",
    "    history_loss_G = []\n",
    "    history_loss_D = []\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    print(f\"ðŸš€ Starting training for {config.NUM_EPOCHS} epochs...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        epoch_loss_D = 0\n",
    "        epoch_loss_G = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for real_imgs, _ in dataloader:\n",
    "            real_imgs = real_imgs.to(config.DEVICE)\n",
    "            \n",
    "            # =====================\n",
    "            # Train Discriminator\n",
    "            # =====================\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            out_real = discriminator(real_imgs)\n",
    "            loss_real = criterion(out_real, real_labels)\n",
    "            \n",
    "            # Fake images\n",
    "            noise = torch.rand(config.BATCH_SIZE, config.N_QUBITS, device=config.DEVICE) * np.pi / 2\n",
    "            fake_imgs = generator(noise)\n",
    "            out_fake = discriminator(fake_imgs.detach())\n",
    "            loss_fake = criterion(out_fake, fake_labels)\n",
    "            \n",
    "            # Update discriminator\n",
    "            loss_D = loss_real + loss_fake\n",
    "            loss_D.backward()\n",
    "            optD.step()\n",
    "            \n",
    "            # =====================\n",
    "            # Train Generator\n",
    "            # =====================\n",
    "            generator.zero_grad()\n",
    "            \n",
    "            # Generator wants discriminator to think fakes are real\n",
    "            out_gen = discriminator(fake_imgs)\n",
    "            loss_G = criterion(out_gen, real_labels)\n",
    "            \n",
    "            loss_G.backward()\n",
    "            optG.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            epoch_loss_D += loss_D.item()\n",
    "            epoch_loss_G += loss_G.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        # Average losses for epoch\n",
    "        avg_loss_D = epoch_loss_D / n_batches\n",
    "        avg_loss_G = epoch_loss_G / n_batches\n",
    "        history_loss_D.append(avg_loss_D)\n",
    "        history_loss_G.append(avg_loss_G)\n",
    "        \n",
    "        # Logging\n",
    "        if epoch % config.LOG_INTERVAL == 0:\n",
    "            print(f\"Epoch {epoch:3d} | Loss D: {avg_loss_D:.4f} | Loss G: {avg_loss_G:.4f}\")\n",
    "            \n",
    "            # Save sample image\n",
    "            with torch.no_grad():\n",
    "                test_noise = torch.rand(1, config.N_QUBITS, device=config.DEVICE) * np.pi / 2\n",
    "                gen_img = generator(test_noise).view(config.IMAGE_SIZE, config.IMAGE_SIZE)\n",
    "                history_images.append(gen_img.cpu().numpy())\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(\"âœ… Training Complete!\")\n",
    "    \n",
    "    # --- Save & Visualize ---\n",
    "    utils.save_checkpoint(generator, discriminator, config.NUM_EPOCHS)\n",
    "    utils.visualize_training_progress(history_images, save_path='training_progress.png')\n",
    "    \n",
    "    return generator, discriminator, history_images\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218b04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ce7ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ PyTorch device: cpu\n",
      "âœ“ Quantum device: default.qubit (torch interface, backprop)\n",
      "ðŸ”¬ Initializing Hybrid Quantum GAN\n",
      "   Device: cpu\n",
      "   Qubits: 5 (1 ancillary)\n",
      "   Generators: 4 (patch size: 16)\n",
      "\n",
      "Loaded 178 samples of digit '0'\n",
      "ðŸš€ Starting training for 50 epochs...\n",
      "--------------------------------------------------\n",
      "Epoch   0 | Loss D: 1.3962 | Loss G: 0.7481\n",
      "Epoch  10 | Loss D: 1.3666 | Loss G: 0.7616\n",
      "Epoch  20 | Loss D: 1.3617 | Loss G: 0.7661\n",
      "Epoch  30 | Loss D: 1.3479 | Loss G: 0.7781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 130\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generator, discriminator, history_images\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m     out_gen \u001b[38;5;241m=\u001b[39m discriminator(fake_imgs)\n\u001b[0;32m     93\u001b[0m     loss_G \u001b[38;5;241m=\u001b[39m criterion(out_gen, real_labels)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     optG\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Accumulate losses\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cnevi\\miniconda3\\envs\\quantum\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cnevi\\miniconda3\\envs\\quantum\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cnevi\\miniconda3\\envs\\quantum\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "\"\"\"\n",
    "Main training script for Hybrid Quantum-Classical GAN.\n",
    "Run this file to start training.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import config\n",
    "import dataset\n",
    "import models\n",
    "import utils\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Main training loop.\"\"\"\n",
    "    \n",
    "    # --- Setup ---\n",
    "    utils.set_seed()\n",
    "    print(f\"ðŸ”¬ Initializing Hybrid Quantum GAN\")\n",
    "    print(f\"   Device: {config.DEVICE}\")\n",
    "    print(f\"   Qubits: {config.N_QUBITS} ({config.N_A_QUBITS} ancillary)\")\n",
    "    print(f\"   Generators: {config.N_GENERATORS} (patch size: {config.PATCH_SIZE})\")\n",
    "    print()\n",
    "    \n",
    "    # Data\n",
    "    dataloader = dataset.get_dataloader()\n",
    "    \n",
    "    # Models\n",
    "    generator = models.PatchQuantumGenerator().to(config.DEVICE)\n",
    "    discriminator = models.Discriminator().to(config.DEVICE)\n",
    "    \n",
    "    # Loss & Optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    optG = optim.SGD(generator.parameters(), lr=config.LR_GENERATOR)\n",
    "    optD = optim.SGD(discriminator.parameters(), lr=config.LR_DISCRIMINATOR)\n",
    "    \n",
    "    # Labels\n",
    "    real_labels = torch.full((config.BATCH_SIZE, 1), 0.9, device=config.DEVICE)\n",
    "    fake_labels = torch.zeros(config.BATCH_SIZE, 1, device=config.DEVICE)\n",
    "    \n",
    "    # History for visualization\n",
    "    history_images = []\n",
    "    history_loss_G = []\n",
    "    history_loss_D = []\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    print(f\"ðŸš€ Starting training for {config.NUM_EPOCHS} epochs...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        epoch_loss_D = 0\n",
    "        epoch_loss_G = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for real_imgs, _ in dataloader:\n",
    "            real_imgs = real_imgs.to(config.DEVICE)\n",
    "            \n",
    "            # =====================\n",
    "            # Train Discriminator\n",
    "            # =====================\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            out_real = discriminator(real_imgs)\n",
    "            loss_real = criterion(out_real, real_labels)\n",
    "            \n",
    "            # Fake images\n",
    "            noise = torch.rand(config.BATCH_SIZE, config.N_QUBITS, device=config.DEVICE) * np.pi / 2\n",
    "            fake_imgs = generator(noise)\n",
    "            out_fake = discriminator(fake_imgs.detach())\n",
    "            loss_fake = criterion(out_fake, fake_labels)\n",
    "            \n",
    "            # Update discriminator\n",
    "            loss_D = loss_real + loss_fake\n",
    "            loss_D.backward()\n",
    "            optD.step()\n",
    "            \n",
    "            # =====================\n",
    "            # Train Generator (3x more often)\n",
    "            # =====================\n",
    "            for _ in range(3):\n",
    "                generator.zero_grad()\n",
    "                \n",
    "                # Generate fresh noise for every step\n",
    "                noise = torch.rand(config.BATCH_SIZE, config.N_QUBITS, device=config.DEVICE) * np.pi / 2\n",
    "                fake_imgs = generator(noise)\n",
    "                \n",
    "                # Generator wants discriminator to think fakes are real\n",
    "                out_gen = discriminator(fake_imgs)\n",
    "                loss_G = criterion(out_gen, real_labels)\n",
    "                \n",
    "                loss_G.backward()\n",
    "                optG.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            epoch_loss_D += loss_D.item()\n",
    "            epoch_loss_G += loss_G.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        # Average losses for epoch\n",
    "        avg_loss_D = epoch_loss_D / n_batches\n",
    "        avg_loss_G = epoch_loss_G / n_batches\n",
    "        history_loss_D.append(avg_loss_D)\n",
    "        history_loss_G.append(avg_loss_G)\n",
    "        \n",
    "        # Logging\n",
    "        if epoch % config.LOG_INTERVAL == 0:\n",
    "            print(f\"Epoch {epoch:3d} | Loss D: {avg_loss_D:.4f} | Loss G: {avg_loss_G:.4f}\")\n",
    "            \n",
    "            # Save sample image\n",
    "            with torch.no_grad():\n",
    "                test_noise = torch.rand(1, config.N_QUBITS, device=config.DEVICE) * np.pi / 2\n",
    "                gen_img = generator(test_noise).view(config.IMAGE_SIZE, config.IMAGE_SIZE)\n",
    "                history_images.append(gen_img.cpu().numpy())\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(\"âœ… Training Complete!\")\n",
    "    \n",
    "    # --- Save & Visualize ---\n",
    "    utils.save_checkpoint(generator, discriminator, config.NUM_EPOCHS)\n",
    "    utils.visualize_training_progress(history_images, save_path='training_progress.png')\n",
    "    \n",
    "    return generator, discriminator, history_images\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6454c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
